{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>polarity</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262996</th>\n",
       "      <td>b'Sun May 03 20:45:40 PDT 2009'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'NO_QUERY'</td>\n",
       "      <td>b\"Man, i'm tired of waiting for the cupcake up...</td>\n",
       "      <td>b'millenniumze'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102121</th>\n",
       "      <td>b'Fri May 29 01:23:43 PDT 2009'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'NO_QUERY'</td>\n",
       "      <td>b\"Shit... It's 2am and I'm wide awake \"</td>\n",
       "      <td>b'anotherJohn'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    date  polarity        query  \\\n",
       "262996   b'Sun May 03 20:45:40 PDT 2009'         0  b'NO_QUERY'   \n",
       "1102121  b'Fri May 29 01:23:43 PDT 2009'         0  b'NO_QUERY'   \n",
       "\n",
       "                                                      text             user  \n",
       "262996   b\"Man, i'm tired of waiting for the cupcake up...  b'millenniumze'  \n",
       "1102121            b\"Shit... It's 2am and I'm wide awake \"   b'anotherJohn'  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tfds.load('sentiment140', split='train', shuffle_files=True)\n",
    "df = tfds.as_dataframe(ds.take(-1))\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Note: Binary classification can be used. \n",
    "\n",
    "Lets review how long the words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bin_polarity'] = df['polarity'].apply(lambda x: 1 if x == 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>(5.287999999999999, 77.1]</td>\n",
       "      <td>(77.1, 148.2]</td>\n",
       "      <td>(148.2, 219.3]</td>\n",
       "      <td>(219.3, 290.4]</td>\n",
       "      <td>(290.4, 361.5]</td>\n",
       "      <td>(361.5, 432.6]</td>\n",
       "      <td>(432.6, 503.7]</td>\n",
       "      <td>(503.7, 574.8]</td>\n",
       "      <td>(574.8, 645.9]</td>\n",
       "      <td>(645.9, 717.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>911101</td>\n",
       "      <td>686081</td>\n",
       "      <td>2448</td>\n",
       "      <td>154</td>\n",
       "      <td>111</td>\n",
       "      <td>66</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0              1               2  \\\n",
       "word_count  (5.287999999999999, 77.1]  (77.1, 148.2]  (148.2, 219.3]   \n",
       "freq                           911101         686081            2448   \n",
       "\n",
       "                         3               4               5               6  \\\n",
       "word_count  (219.3, 290.4]  (290.4, 361.5]  (361.5, 432.6]  (432.6, 503.7]   \n",
       "freq                   154             111              66              21   \n",
       "\n",
       "                         7               8               9  \n",
       "word_count  (503.7, 574.8]  (574.8, 645.9]  (645.9, 717.0]  \n",
       "freq                     9               6               3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(df['length_of_text'].value_counts(bins=10\n",
    "                                        ).sort_index()).reset_index().rename(\n",
    "                                        columns={'index':'word_count','length_of_text':'freq'}).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the RNN is that we take just the output of the final word (unless we're doing a bidirectional format, or a concatenated format where we concatenate the output of all the words)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating X values\n",
    "\n",
    "The text is in byte form, so we need to convert it to string form, and then use the split functionality to convert to a list. We ignore the first two characters which are a side effect of the conversion, and the last element in the string which is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns names: ['date', 'polarity', 'query', 'text', 'user', 'length_of_text', 'bin_polarity', 'split_words', 'txt_length']\n"
     ]
    }
   ],
   "source": [
    "print(f'columns names: {list(df.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separating the words into a list of words\n",
    "df['split_words'] = df['text'].apply(lambda x: str(x)[2:].split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the length of words\n",
    "df['txt_length'] = df['split_words'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.4, 12.8]      509407\n",
       "(12.8, 19.2]     421913\n",
       "(-0.065, 6.4]    335661\n",
       "(19.2, 25.6]     267707\n",
       "(25.6, 32.0]      65097\n",
       "(32.0, 38.4]        206\n",
       "(38.4, 44.8]          6\n",
       "(57.6, 64.0]          2\n",
       "(51.2, 57.6]          1\n",
       "(44.8, 51.2]          0\n",
       "Name: txt_length, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['txt_length'].value_counts(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Very few tweets are over 30 words, so we will create an RNN based on 30 words\n",
    "\n",
    "We now need to create a words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_words = 2000\n",
    "top_2k_words = list(df['split_words'].explode().value_counts()[:no_words].index)\n",
    "\n",
    "word_dict_2k = {}\n",
    "for idx, word in enumerate(top_2k_words):\n",
    "    word_dict_2k[idx+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create additional values for 'word is over' and 'unknown'\n",
    "word_dict_2k[no_words+1] = 'word_over'\n",
    "word_dict_2k[0] = 'UNKNOWN-WORD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict_reversed = {}\n",
    "for key, value in word_dict_2k.items():\n",
    "    word_dict_reversed[value] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Our X values need to be 2000 x 30 x m, one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with a smaller set for now\n",
    "df_size = 40000\n",
    "reduced_df = df.iloc[:df_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the words in numeric index format\n",
    "x = reduced_df['split_words'].apply(lambda x: np.array([word_dict_reversed[word] if word in word_dict_reversed.keys() else 0 for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''we're going to make all the x values the same length'''\n",
    "array_x = np.zeros((df_size,30)) #blank array to put them in\n",
    "for idx,arr in enumerate(x):\n",
    "    leng = len(arr) \n",
    "    #get length, and fork based on current size\n",
    "    if leng > 30:\n",
    "        array_x[idx] = arr[:30] #just take first 30 values\n",
    "    elif leng < 30:\n",
    "        array_x[idx] = np.append(arr,np.zeros(30-leng)+no_words+1) #append 30 minus the current length -1s\n",
    "#put examples on the columns\n",
    "array_x = array_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now one hot encode them'''\n",
    "one_hot_x_40k = np.zeros((2002,30,df_size))\n",
    "for row_idx, row in enumerate(array_x):\n",
    "\n",
    "    for exam_idx, word_val in enumerate(row):\n",
    "\n",
    "        one_hot_x_40k[int(word_val),row_idx,exam_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_x[29,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We've used 2002 in order to incorporatate the 2001th word (end of word) and unknown index. We can need to create a mask which tells the machine to skip if the mask is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_x = np.zeros((30,df_size))\n",
    "for idx, time_p in enumerate(mask_x):\n",
    "    for idxx, example in enumerate(time_p):\n",
    "        if array_x[idx,idxx] == 2001:\n",
    "\n",
    "            mask_x[idx,idxx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "OK so we have our x inputs. Mask x, shaped 30 x 40000, and the actual onehotencoded x values, of shape 2001, 30, 40000\n",
    "\n",
    "In the basic RNN, ignoring the last stage for a second, each cell has three weights matrixes.\n",
    "\n",
    "WAa - the weights applied to the previous cells outputs\n",
    "\n",
    "WAx - the weights applied to the X values\n",
    "\n",
    "WaB - a bias term. \n",
    "\n",
    "We have to make a choice of how large each cell is, and then initialise the weights. We'll use a Xavier initialization for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try a cell size of 50\n",
    "cell_size = 50\n",
    "WAa = np.zeros(())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
